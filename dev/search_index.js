var documenterSearchIndex = {"docs":
[{"location":"problems/problems.html#Decision-problems","page":"Decision problems","title":"Decision problems","text":"","category":"section"},{"location":"problems/problems.html","page":"Decision problems","title":"Decision problems","text":"Decision problems join an objective (that is, a DecisionMetric) with a model (that is, a DecisionNetwork). They also specify initial distributions for random variables in the problem.","category":"page"},{"location":"problems/problems.html","page":"Decision problems","title":"Decision problems","text":"Note the distinction between a decision problem (MDP(...)) and the decision network underlying that problem (MDP_DN(...)). ","category":"page"},{"location":"problems/problems.html#DecisionProblems.DecisionProblem","page":"Decision problems","title":"DecisionProblems.DecisionProblem","text":"DecisionProblem\n\nA decision problem, formally stated: a union of a model, given as a DecisionNetwork, an objective, given as a DecisionNetwork, and an optional initial distribution, given as a ConditionalDist with no conditions.\n\n\n\n\n\n","category":"type"},{"location":"problems/problems.html#DecisionProblems.objective","page":"Decision problems","title":"DecisionProblems.objective","text":"objective(dp::DecisionProblem)\n\nGive the DecisionMetric that is the objective of dp.\n\n\n\n\n\n","category":"function"},{"location":"problems/problems.html#DecisionProblems.model","page":"Decision problems","title":"DecisionProblems.model","text":"model(dp::DecisionProblem)\n\nGive the DecisionNetwork that is the model for dp.\n\n\n\n\n\n","category":"function"},{"location":"problems/problems.html#DecisionProblems.initial","page":"Decision problems","title":"DecisionProblems.initial","text":"initial(dp::DecisionProblem, s::Symbol)\ninitial(dp::DecisionProblem)\n\nGive an initial value for the random variable s in problem dp (or a NamedTuple for all random variables for which an initialization is specified, if s is not given).\n\n\n\n\n\n","category":"function"},{"location":"problems/problems.html#Named-decision-problems","page":"Decision problems","title":"Named decision problems","text":"","category":"section"},{"location":"problems/problems.html","page":"Decision problems","title":"Decision problems","text":"Like DecisionNetworks, Decisions.jl provides explicit names for some common decision problems:","category":"page"},{"location":"problems/problems.html#DecisionProblems.MDP","page":"Decision problems","title":"DecisionProblems.MDP","text":"const MDP = DecisionProblem{<: DiscountedReward, <: MDP_DN}\n\nA Markov decision process.\n\n\n\n\n\n","category":"type"},{"location":"problems/problems.html#DecisionProblems.POMDP","page":"Decision problems","title":"DecisionProblems.POMDP","text":"const POMDP = DecisionProblem{<: DiscountedReward, <: POMDP_DN}\n\nA partially observable Markov decision process.\n\n\n\n\n\n","category":"type"},{"location":"problems/problems.html#DecisionProblems.MG","page":"Decision problems","title":"DecisionProblems.MG","text":"const MG = DecisionProblem{<: DiscountedReward, <: MG_DN}\n\nA Markov game.\n\n\n\n\n\n","category":"type"},{"location":"problems/problems.html#Transforming-decision-problems","page":"Decision problems","title":"Transforming decision problems","text":"","category":"section"},{"location":"problems/problems.html","page":"Decision problems","title":"Decision problems","text":"By default, calling a transformation on a DecisionProblem will transform the underlying DecisionNetwork (while leaving the objective unchanged).","category":"page"},{"location":"networks/faqs.html#FAQs","page":"FAQs","title":"FAQs","text":"","category":"section"},{"location":"networks/faqs.html#How-do-I-represent-terminal-states?","page":"FAQs","title":"How do I represent terminal states?","text":"","category":"section"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"Rather than using dedicated functions that check for terminality (like in POMDPs.jl), Decisions.jl assumes conditional distributions return terminal. when terminal conditions are reached. See also Terminal, isterminal.","category":"page"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"There are two main benefits of this approach: ","category":"page"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"Any node can be terminal (allowing, for instance, terminal actions)\nUnecessary terminality checks can be avoided during simualtion: e.g., if a particular check in a conditional distribution already ensures a nonterminal output.","category":"page"},{"location":"networks/faqs.html#How-do-I-have-a-variable-number-of-agents-in-a-decision-network-/-graph?","page":"FAQs","title":"How do I have a variable number of agents in a decision network / graph?","text":"","category":"section"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"The ranges type parameter represents the number of agents (and other plate indices). If you'd like to represent the class of decision networks of a particular type, but without any specific number of agents or implemented conditional distributions, this can be represented out of the box with a DecisionGraph (which, under the hood, will represent DecisionNetwork{your_nodes, your_dynamic_pairs, ranges} where {ranges})","category":"page"},{"location":"networks/faqs.html#Why-are-random-variables-keyword-arguments?","page":"FAQs","title":"Why are random variables keyword arguments?","text":"","category":"section"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"In short: Unlike arguments of functions in general, conditions of conditional distributions are often left unordered in common notation. We expect p(⋅ | x, y) to be the same as p(⋅ |y, x).","category":"page"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"To be more specific, when an argument order is imposed on conditional distributions, the consequences can be very confusing: for instance, we know the random variables in a MDP's reward distribution are traditionally ordered [s, a, sp], but this disagrees with the lexical order imposed by DecisionGraph to ensure order invariance. When more conditions are added and removed by transformations, the \"right\" ordering becomes entirely unclear.","category":"page"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"Using keyword arguments instead bypasses these problems, with some free syntactic sugar on top.","category":"page"},{"location":"networks/faqs.html#What-exactly-are-the-m/mp-nodes?","page":"FAQs","title":"What exactly are the m/mp nodes?","text":"","category":"section"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"These are the \"memory\" / \"successor memory\" nodes used in partially observable standard Markov family networks. In single-agent theory, these are traditionally referred to as beliefs, and the implementation of mp is the belief updater. ","category":"page"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"Agent behavior (including a and mp), like all nodes, is represented with stateless conditional distributions, meaning that agent internal state must be passed along in the network itself. This is the use of the memory nodes. We consider it crucial to explicitly model agent internal state in the network, rather than just allowing action distributions to be stateful, for several reasons:","category":"page"},{"location":"networks/faqs.html","page":"FAQs","title":"FAQs","text":"Conditional distributions are, fundamentally, not stateful. Therefore, neither are policies. (Or, in broader terms: this approach better connects Decisions.jl to the underlying mathematics, one of the major package objectives.)\nWe want to definitively compare agents based on the type, quantity, and quality of information collected during execution within an environment. More importantly, we want to distinguish this information from data gathered over multiple executions of a simulated environment (which may or may not be related to in-execution memory).\nDetermining uniqueness of agent history / belief / etc. is useful for efficiency reasons.\nFinite state controllers (FSCs) are the most general policy (even provably beyond DNNs, belief tracking, state compression, and so on) and they have have this form.\nIn multiagent problems, the relationship between memory nodes causes complex and unexpected interactions (for instance, infinite regress in the hierarchy of beliefs.) ","category":"page"},{"location":"problems/algorithms.html#Algorithms","page":"Algorithms","title":"Algorithms","text":"","category":"section"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"A decision algorithm takes in a DecisionProblem and outputs conditional distributions for action nodes in the problem model based on the problem objective.","category":"page"},{"location":"problems/algorithms.html#A-warning-about-decision-environments","page":"Algorithms","title":"A warning about decision environments","text":"","category":"section"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"In DecisionProblems.jl, no distinction is made between the model of an environment (expressed by model(::DecisionProblem)) and the environment itself. As such, agents are free to use the problem model in any way they choose, but there is no guarantee that the provided DecisionProblem is reflective of a \"real\" environment. More specifically, there is no structure defining the way in which an algorithm would get data from the real environment, as they would in a traditional learning pipeline. Relatedly, in multi-agent settings, complex interactions between agents that may differ in the training and execution stages affect the problem significantly, and DecisionProblems alone does not specify how agents receive information about other agents.","category":"page"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"For algorithm design and prototyping purposes it's typically fine to just use DecisionProblems and wrap it in your preferred setup for dealing with the ground truth environment. However, if you'd like to make totally exact comparisons that ensure algorithms are being used in identical settings, or you're just tired of writing this sort of boilerplate code, you may wish to additionally use DecisionSettings.jl.","category":"page"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"todo: Todo\nDecisionSettings is still undergoing initial development. It is not yet suitable for use.","category":"page"},{"location":"problems/algorithms.html#Using-decision-algorithms","page":"Algorithms","title":"Using decision algorithms","text":"","category":"section"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"Algorithms have a sole method to define, solve:","category":"page"},{"location":"problems/algorithms.html#DecisionProblems.solve","page":"Algorithms","title":"DecisionProblems.solve","text":"solve(da::DecisionAlgorithm, model::DecisionProblem)\n\nApply a decision algorithm to a model problem.\n\nShould output a NamedTuple, where each name is an action node of the model's DecisionNetwork, and each value is its solution ConditionalDist. \n\n\n\n\n\n","category":"function"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"solve should return a NamedTuple, where each name is a random variable for an action node and each value is an implementation for that node. ","category":"page"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"With this defined, an algorithm's performance can be simulated:","category":"page"},{"location":"problems/algorithms.html#DecisionProblems.simulate!","page":"Algorithms","title":"DecisionProblems.simulate!","text":"simulate!(dp::DecisionProblem, da::DecisionAlgorithm...; metrics::DecisionMetric...)\nsimulate!(fn, dp::DecisionProblem, da::DecisionAlgorithm...; metrics::DecisionMetric...)\n\nSolve decision problem dp with algorithm(s) da, merge the behavior provided by the algorithms into the decision network network(dp), and roll out that network, aggregating metrics, until terminal conditions are reached.\n\nReturns a NamedTuple of metric outputs with names matching the keywords metrics, with an additional entry always named :objective mapping to the output of objective(dp).\n\nIf fn is provided, it is passed through to sample to enable early termination.\n\n\n\n\n\n","category":"function"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"simulate! allows one to pass through additional metrics other than the objective of the problem, which can be useful in monitoring side considerations or tracing the path of the agent. Note that simulate! is not a pure function: it calls reset! and aggregate! on the provided metrics.","category":"page"},{"location":"problems/algorithms.html#Multiagency-in-solvers","page":"Algorithms","title":"Multiagency in solvers","text":"","category":"section"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"You may notice that in a multiagent situation (for instance an MG), there is only a single action node to implement (which has an agent index). This makes it somewhat confusing to write a solver for only a single agent. In other words, a single solve! is expected to provided all the missing agent behavior in the model.","category":"page"},{"location":"problems/algorithms.html","page":"Algorithms","title":"Algorithms","text":"Here it is important to differentiate algorithms from agents. A decision algorithm just fills in nodes in a model according to an objective. An agent, on the other hand, has complex interactions with and about other agents. Since these interactions aren't specified in a decision algorithm alone, decision algorithms don't have an identity: there is no \"ego\" agent to a decision algorithm. As such, decision algorithms make assumptions about the relationship between players: For instance, in a game-theoretic setting it is assumed all agents act mutually rationally, and when one \"solves\" a game (i.e., for a Nash equilibrium), distributions for all players are given.","category":"page"},{"location":"networks/dns.html#Decision-networks","page":"Decision networks","title":"Decision networks","text":"","category":"section"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"The fundamental unit of problem description in Decisions.jl is the (dynamic) decision network or (D)DN (variously related to or synonymous with \"influence diagram,\" \"generalized Bayesian network,\" and \"decision diagram\"). A decision network is a directed acyclic graph where each node is the distribution of a random variable conditioned on some other nodes in the network. ","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"In Decisions.jl, DNs consist of two components:","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"A decision graph, which gives the abstract definition of the relationships between random variables in the network, and \nAn implementation, which provides some of the conditional distributions in the network. Nodes with no implemented distribution are considered decision nodes. ","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"The decision graph lives in type space: it is given by the Type{<:DecisionNetwork} (aliased to DecisionGraph). This allows Decisions.jl to perform computation about the structure of a DN at compile time. DecisionNetwork instances additionally carry implementation information.","category":"page"},{"location":"networks/dns.html#DecisionNetworks.DecisionNetwork","page":"Decision networks","title":"DecisionNetworks.DecisionNetwork","text":"DecisionNetwork\n\nRepresentation of a decision network based on an underlying directed acyclic graph.\n\n\n\n\n\n","category":"type"},{"location":"networks/dns.html#DecisionNetworks.DecisionGraph","page":"Decision networks","title":"DecisionNetworks.DecisionGraph","text":"const DecisionGraph = Type{<:DecisionNetwork}\nDecisionGraph(nodes, dynamic_pairs=nothing, ranges=nothing)\n\nA decision graph: the graph structure of a decision network, with none of the distributions implemented. \n\nIf dynamic_pairs or ranges is nothing, the corresponding DecisionNetwork type parameter is left unspecified. (This way, it is possible to define a DecisionGraph without knowing the dynamic pairs or ranges ahead of time.) \n\n\n\n\n\n","category":"type"},{"location":"networks/dns.html#DecisionNetworks.implementation","page":"Decision networks","title":"DecisionNetworks.implementation","text":"implementation(dn::DecisionNetwork)\n\nGive the conditional distributions implementing the nodes of a decision network as a NamedTuple mapping node names to distributions.\n\n\n\n\n\n","category":"function"},{"location":"networks/dns.html#Instantiating-DNs","page":"Decision networks","title":"Instantiating DNs","text":"","category":"section"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"Every node in DecisionNetworks.jl is a random variable, named with a Symbol. Values and distributions associated with them are passed around as keyword arguments (a pattern seen in many places in Decisions.jl). So, to make a new DN, we pass these distributions into the constructor for a Type{<:DecisionNetwork}. (The Type{<:DecisionNetwork} itself gives the decision graph - which tells us how these random variables condition each other.)","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"There are several ways to get a Type{<:DecisionNetwork} that can be instantiated. For instance, we might use the premade MDP_DN network type, which underlies Markov decision processes:","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"my_dn = MDP_DN(; \n    sp = (rng; s, a) -> rand(rng), \n    r = (rng; s, a, sp) -> s + a\n)","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"tip: Tip\nFunctions and Spaces that are passed to the constructor as implementations for  distributions are automatically converted to ConditionalDists.","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"The pretty-printed output tells us something about the DN: it has nodes named a, r, s, and sp, it has the given conditionings for those nodes, and it's a DDN where sp becomes s at each iterate. Indeed, all Markov decision problems have decision network nodes s (state), sp (successor state), r (reward), and a (action). The distributions for sp, r, and a are the state transition, reward function, and policy respectively. In the parentheses, we see that we've provided implementations for r and sp, but a has no implementation; that is, it is a decision node.","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"Note that the type MDP_DN - that is, the decision graph - tells us everything there is to know about the network structure of an MDP. The prenamed decision network types defined by DecisionNetworks.jl cover a few commonly used network structures, but later sections in this documentation also deal with defining arbitrary decision graphs.","category":"page"},{"location":"networks/dns.html#Sampling-DNs","page":"Decision networks","title":"Sampling DNs","text":"","category":"section"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"As mentioned above, every node in a DN is a random variable with a Symbol name. Conditional distributions for nodes can be obtained with index notation:","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"my_dn[:sp]","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"This gives the conditional distribution for sp in this DDN (that is, the state transition). All sorts of useful functions for algorithm writers are defined on conditional distributions, documented on their own manual page.","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"An entire DN or DDN can be sampled given inputs with sample. In particular, the behavior argument is used to provide implementations for all distributions not already implemented in the network: that is, implementations for the action nodes.","category":"page"},{"location":"networks/dns.html#DecisionNetworks.sample","page":"Decision networks","title":"DecisionNetworks.sample","text":"sample(fn = (_) -> false, dn::DecisionNetwork [, decisions::NamedTuple, input::NamedTuple, output::Tuple])\n\nSample nodes or plates out in decision network dn based on input values in and node implementations provided by decisions and dn.implementation. fn, if present, executes upon each iteration of a (dynamic) network on a NamedTuple mapping the names out to their values, and stops when fn returns true.\n\nReturns Terminal() if a terminal condition is reached. Otherwise, returns a NamedTuple mapping the names out to their values after the last (or only) iteration. \n\nOnly ancestors of out, up to (but not including) the nodes in in, are sampled. If any of the sampled nodes are not implemented by either dn.implementation or decisions, an error is thrown. If both dn.implementation and decisions specify the same node, the implementation in decisions is preferred.\n\n\n\n\n\n","category":"function"},{"location":"networks/dns.html#Decision-network-traits","page":"Decision networks","title":"Decision network traits","text":"","category":"section"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"Decisions.jl defines a number of traits on various objects, especially decision networks. They are implemented using the Holy trait pattern. The full documentation for all traits is available here.","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"Traits on decision networks are used to give an exact idea of how particular semantic concepts, like \"partial observability\" and \"sequentiality\", correspond to actual decision networks. These traits can be combined to form new networks.","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"todo: Todo\nTraits are not automatically applied to @markov_alias'd networks.","category":"page"},{"location":"networks/dns.html","page":"Decision networks","title":"Decision networks","text":"Trait Possibilities supplied by Decisions.jl Description\nMultiagency NoAgent, SingleAgent, DefiniteAgent, IndefiniteAgent Number of agents in a problem (and whether that number is known)\nObservability FullyObservable, PartiallyObservable Whether input into decision nodes is a sufficient statistic for other nodes in the DN\nCentralization Centralized, Decentralized Whether input into decision nodes is the same across agents\nMemoryPresence MemoryPresent, MemoryAbsent Whether there is an agent-defined information aggregator across DDN iterates\nRewardStyle NoReward, SingleReward, DefiniteRewards, IndefiniteRewards Whether a \"reward\" node is present, how many rewards it represents, and what it is conditioned on\nStatefulness Stateful, Stateless, AgentFactored Presence and structure of a \"state\" node\nSequentiality Simultaneous, Sequential Whether decision nodes are calculable in parallel\nCooperation Cooperative, Competitive, Individual Whether agents are implied to share or interfere with each others' objectives\nAgentCorrelation Correlated, Uncorrelated Whether agents jointly or independently sample their decisions\nTimestepStyle FixedTime, SemiMarkov Whether the network is implied to represent a semi-Markov problem","category":"page"},{"location":"networks/transformations.html#Transformations","page":"Transformations","title":"Transformations","text":"","category":"section"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"One of Decisions.jl's greatest strengths is its ability to flexibly and precisely modify decision networks. Decision problems can be changed from multiple to single agents, full to partial observability, and all sorts of other changes in one line by transforming the underlying decision network.","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"Such transformations are subtypes of the DNTransformation base class. Transformations can affect only implemented DecisionNetworks, only their DecisionGraphs, or both. ","category":"page"},{"location":"networks/transformations.html#DecisionNetworks.DNTransformation","page":"Transformations","title":"DecisionNetworks.DNTransformation","text":"abstract type DNTransformation\n\nAbstract base class for transformations of decision networks and graphs.\n\nTransformations are callable: (t::DNTransformation)(p) = transform(t, p).\n\n\n\n\n\n","category":"type"},{"location":"networks/transformations.html#DecisionNetworks.transform","page":"Transformations","title":"DecisionNetworks.transform","text":"transform(t::DNTransformation, d::DecisionNetwork)\ntransform(t::DNTransformation, d::DecisionGraph)\n\nApply transformation t to decision network or graph d, returning a new network or graph.\n\n\n\n\n\n","category":"function"},{"location":"networks/transformations.html#Provided-transformations","page":"Transformations","title":"Provided transformations","text":"","category":"section"},{"location":"networks/transformations.html#DecisionNetworks.Insert","page":"Transformations","title":"DecisionNetworks.Insert","text":"Insert <: DNTransformation\nInsert(nodes...)\n\nInsert one or more nodes into a decision graph or decision network.\n\nnodes are supplied as node definitions; that is, pairs of the form (::ConditioningGroup...) => ::Plate.\n\n\n\n\n\n","category":"type"},{"location":"networks/transformations.html#DecisionNetworks.Implement","page":"Transformations","title":"DecisionNetworks.Implement","text":"Implement <: DNTransformation\nImplement(; impls::ConditionalDist...)\n\nAugment a decision network with conditional distribution(s) implementing one or more of its nodes.\n\nConditional distributions are supplied to nodes matching the names of their kwargs. If a distribution is supplied for a node that has one, the existing distribution is replaced. \n\n\n\n\n\n","category":"type"},{"location":"networks/transformations.html#DecisionNetworks.Unimplement","page":"Transformations","title":"DecisionNetworks.Unimplement","text":"Unimplement <: DNTransformation\nUnimplement(nodes...)\n\nRemove the conditional distribution(s) implementing one or more nodes in the decision network, if they exist. \n\nThe node names are given as Symbols.\n\n\n\n\n\n","category":"type"},{"location":"networks/transformations.html#DecisionNetworks.Recondition","page":"Transformations","title":"DecisionNetworks.Recondition","text":"Recondition <: DNTransformation\nRecondition(; nodes...)\n\nChange the conditioning of one or more nodes in a decision graph (not a decision network).\n\nNew conditionings are supplied as tuples of ConditioningGroups, with the keyword name giving the node they condition.\n\n\n\n\n\n","category":"type"},{"location":"networks/transformations.html#DecisionNetworks.IndexExplode","page":"Transformations","title":"DecisionNetworks.IndexExplode","text":"IndexExplode <: DNTransformation\nIndexExplode(idx; sep='_')\n\nSplit all plates a in a decision network or graph over index idx into nodes a_1, a_2, ..., a_N, where N is given by ranges.\n\nIn a decision network, when a node with an implementation dist is exploded along axis i, the resulting subnodes have distributions fix(dist; i=1), fix(dist; i=2), etc.\n\n\n\n\n\n","category":"type"},{"location":"networks/transformations.html#DecisionNetworks.MergeForward","page":"Transformations","title":"DecisionNetworks.MergeForward","text":"MergeForward <: DNTransformation\nMergeForward(nodes...)\n\nMerges nodes named in nodes forward in a decision network or decision graph: for each such node n, nodes that n as an input now have the inputs of n as inputs (and n is removed from the network).\n\nIn a decision network, nodes with implemented distributions have those distributions merged with MergedDist.\n\n\n\n\n\n","category":"type"},{"location":"networks/transformations.html#DecisionNetworks.Rename","page":"Transformations","title":"DecisionNetworks.Rename","text":"Rename <: DNTransformation\nRename(; names...)\n\nRename nodes in a decision network.\n\nEach keyword argument maps an old to new node name.\n\n\n\n\n\n","category":"type"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"todo: Todo\nMany useful transformations are still missing from DecisionNetworks.jl, and those that do exist have yet to be thoroughly tested.","category":"page"},{"location":"networks/transformations.html#Examples","page":"Transformations","title":"Examples","text":"","category":"section"},{"location":"networks/transformations.html#Transforming-a-Markov-game-into-an-MDP","page":"Transformations","title":"Transforming a Markov game into an MDP","text":"","category":"section"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"One might want to interpret a Markov game as an ordinary MDP by assuming some opponent behavior. This is a matter of a few transformations.","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"We'll start with some Markov game implemented with arbitrary distributions (passed in as Functions and automatically converted). Note that we specify the ranges for the plates of the Markov game - that is, the number of agents - in the type parameter, so this is a two player game. ","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"my_mg = MG_DN{(; i=2)}(;\n    sp = (rng; a, s) -> \"sp for actions $a\",\n    r = (rng; a, s, sp, i) -> \"r$i\" \n)","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"We can turn all the agent-indexed plates into individual nodes with IndexExplode (in this case there are only two apiece for a and r).","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"my_dn = my_mg |> IndexExplode(:i) ","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"This automatically edits the distributions for sp and r to fit the new arrangement. Now, we can provide an implementation for only the opponent policy:","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"my_dn = my_dn |> Implement(;\n    a_2 = (rng; kwargs...) -> \"a2\"\n)","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"In doing this, we're treating the opponent as part of the model. We can MergeForward the opponent nodes into the state transition (and get rid of the irrelevant opponent reward):","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"my_dn = my_dn |> MergeForward(:r_2, :a_2)","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"You may notice that this is not technically a MDP_DN: it has nodes a_1 and r_1, rather than a and r. So, finally, we egoistically rename those nodes:","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"my_mdp = my_dn|> Rename(; a_1=:a, r_1=:r)","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"As you can see, this network is indeed the DN for an MDP now.","category":"page"},{"location":"networks/transformations.html#Transforming-a-POMDP-into-an-MDP","page":"Transformations","title":"Transforming a POMDP into an MDP","text":"","category":"section"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"It is possible for transformations to be lossy: the output network or graph is not necessarily equivalent to the input. This can cause some unexpected behavior. As an example, let's strip the partial observability from a POMDP.","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"For variety, we'll operate on the DecisionGraph POMDP_DN rather than the DecisionNetwork POMDP_DN(...). ","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"node_names(POMDP_DN)","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"Notice that we include the \"memory nodes\" m and mp by default here. One might expect to be able to simply MergeForward the memory and observation nodes, removing all the partial-observability machinery, to reach a model where a is directly conditioned on s. However, in reality, we see something slightly different:","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"My_DN = POMDP_DN |> MergeForward(:m, :mp, :o)\nconditions(My_DN, :a)","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"Instead of being conditioned on s, a is conditioned on nothing at all! This is because m is an input to the network (except in iterates past the first, where it gets the output of mp), and therefore unconditioned. When it is merged into a, a then has no conditions either.","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"We can recover the MDP structure by explicitly conditioning the a node:","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"My_DN = POMDP_DN |> MergeForward(:m, :mp, :o) |> Recondition(; a=(Dense(:s),))\nconditions(My_DN, :a)","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"Finally, let's make a DecisionNetwork with the new DecisionGraph and make sure it's actually an MDP:","category":"page"},{"location":"networks/transformations.html","page":"Transformations","title":"Transformations","text":"My_DN()","category":"page"},{"location":"networks/internals.html#Advanced:-Internals","page":"Advanced: Internals","title":"Advanced: Internals","text":"","category":"section"},{"location":"networks/internals.html#More-structural-ConditionalDists","page":"Advanced: Internals","title":"More structural ConditionalDists","text":"","category":"section"},{"location":"networks/internals.html","page":"Advanced: Internals","title":"Advanced: Internals","text":"There are some structural ConditionalDists that are primarily used in transformations. These distributions act as wrappers around others, which can cause a significant performance drop as transformations are aggregated. As such, they are considered unstable and are likely to be subject to significant additional refactoring.","category":"page"},{"location":"networks/internals.html#DecisionNetworks.RenamedDist","page":"Advanced: Internals","title":"DecisionNetworks.RenamedDist","text":"RenamedDist <: ConditionalDist\n\nA conditional distribution that wraps another, renaming the conditioning variables.\n\n\n\n\n\n","category":"type"},{"location":"networks/internals.html#DecisionNetworks.MergedDist","page":"Advanced: Internals","title":"DecisionNetworks.MergedDist","text":"MergedDist <: ConditionalDist\n\nA conditional distribution which merges two subdistributions, using one as an input for another.\n\n\n\n\n\n","category":"type"},{"location":"networks/internals.html#Tools-for-traversing-DecisionNetworks","page":"Advanced: Internals","title":"Tools for traversing DecisionNetworks","text":"","category":"section"},{"location":"networks/internals.html","page":"Advanced: Internals","title":"Advanced: Internals","text":"These are the tools used at compile time to generate fast sampling code and nonambiguous networks.","category":"page"},{"location":"networks/internals.html#DecisionNetworks._standardize_dn_type","page":"Advanced: Internals","title":"DecisionNetworks._standardize_dn_type","text":"_get_dn_type_params(nodes, dynamic_pairs=nothing, ranges=nothing)\n\nStandardize the type parameters for a decision network (imposing an order, making them the correct types, etc.)\n\nOutput is a 3-tuple. nodes is required. If dynamic_pairs and ranges are not provided, nothing is returned for them.\n\n\n\n\n\n","category":"function"},{"location":"networks/internals.html#DecisionNetworks._crawl_dn","page":"Advanced: Internals","title":"DecisionNetworks._crawl_dn","text":"_crawl_dn(dn, constituents, input, output)\n\nGive all nodes required to compute nodes output of dn, given that nodes input are known, in order.\n\n\n\n\n\n","category":"function"},{"location":"networks/internals.html#DecisionNetworks._node_order","page":"Advanced: Internals","title":"DecisionNetworks._node_order","text":"_node_order(dn, rv)\n\nCalculate the order of the random variable named rv in decision network dn; that is, n such that rv is conditioned on random variables of at most order n-1. \n\n\n\n\n\n","category":"function"},{"location":"networks/internals.html#DecisionNetworks._make_node_assignment","page":"Advanced: Internals","title":"DecisionNetworks._make_node_assignment","text":"_make_node_assignment(dn, id; in_place=false)\n\nGenerate an Expr that updates random variable id based on decision network dn.\n\n\n\n\n\n","category":"function"},{"location":"networks/internals.html#DecisionNetworks._make_node_initialization","page":"Advanced: Internals","title":"DecisionNetworks._make_node_initialization","text":"_make_node_initialization(dn, id)\n\nInfer an expression that initializes an empty MArray of the correct size and name for node id in dn.\n\n\n\n\n\n","category":"function"},{"location":"networks/internals.html#Random-variable-groups","page":"Advanced: Internals","title":"Random variable groups","text":"","category":"section"},{"location":"networks/internals.html#DecisionNetworks.RVGroup","page":"Advanced: Internals","title":"DecisionNetworks.RVGroup","text":"abstract type RVGroup{id, idxs}\n\nAbstract base type representing a group of random variables, named id, over axes with indices idxs.\n\n\n\n\n\n","category":"type"},{"location":"networks/internals.html#DecisionNetworks.expr","page":"Advanced: Internals","title":"DecisionNetworks.expr","text":"expr(::RVGroup)\n\nGive an indexing expression for a group of random variables that specifies single variables in the group.\n\n\n\n\n\n","category":"function"},{"location":"networks/internals.html#Utilities","page":"Advanced: Internals","title":"Utilities","text":"","category":"section"},{"location":"networks/internals.html","page":"Advanced: Internals","title":"Advanced: Internals","text":"Simple utilities used across the project:","category":"page"},{"location":"networks/internals.html#DecisionNetworks._sortkeys","page":"Advanced: Internals","title":"DecisionNetworks._sortkeys","text":"_sortkeys(::NamedTuple)\n\nSort the keys in a NamedTuple (to enforce order invariance).\n\n\n\n\n\n","category":"function"},{"location":"networks/internals.html#DecisionNetworks._sorted_tuple","page":"Advanced: Internals","title":"DecisionNetworks._sorted_tuple","text":"_sorted_tuple(v)\n\nGive a tuple containing the elements in v, sorted according to sort.\n\nUseful for imposing a structure on a Tuple used as a type parameter.\n\n\n\n\n\n","category":"function"},{"location":"networks/interoperability.html#Interoperability","page":"Interoperability","title":"Interoperability","text":"","category":"section"},{"location":"networks/interoperability.html#Graphs.jl","page":"Interoperability","title":"Graphs.jl","text":"","category":"section"},{"location":"networks/interoperability.html","page":"Interoperability","title":"Interoperability","text":"DecisionNetworks and DecisionGraphs can be converted into the Graphs.jl ecosystem. They are interpreted as SimpleDiGraphs, with the nodes in the same order as given by node_names.","category":"page"},{"location":"networks/interoperability.html","page":"Interoperability","title":"Interoperability","text":"Beware that this strips several important pieces of information, leaving only the underlying graph:","category":"page"},{"location":"networks/interoperability.html","page":"Interoperability","title":"Interoperability","text":"Implementations (conditional distributions) for all nodes\nNode names\nIndependence relationships between plates and their conditions","category":"page"},{"location":"networks/interoperability.html#DecisionNetworks.as_graphs_jl","page":"Interoperability","title":"DecisionNetworks.as_graphs_jl","text":"as_graphs_jl(djl)\n\nGive a Graphs.jl-style directed graph (that is, a SimpleDiGraph) corresponding to the  DecisionGraph or DecisionNetwork djl.\n\n\n\n\n\n","category":"function"},{"location":"problems/metrics.html#Metrics","page":"Metrics","title":"Metrics","text":"","category":"section"},{"location":"problems/metrics.html","page":"Metrics","title":"Metrics","text":"Decision networks alone have no concepts of solution or objective - they are just environment models. At most, they have action nodes that are not yet implemented, to be determined \"somewhere else\" then used as input to sample and the like. ","category":"page"},{"location":"problems/metrics.html","page":"Metrics","title":"Metrics","text":"DecisionProblems.jl provides the missing link. A decision problem joins a decision network and a metric, which indicates an optimization objective over the random variables in the network. Decision algorithms implement the missing distributions in the decision network in order to optimize that metric. ","category":"page"},{"location":"problems/metrics.html#Using-decision-metrics","page":"Metrics","title":"Using decision metrics","text":"","category":"section"},{"location":"problems/metrics.html","page":"Metrics","title":"Metrics","text":"DecisionMetric and its descendants define objectives over decision networks. Decision metrics vary from simple benchmarks (\"how many steps did this DDN run?\") to ubiquitous objective concepts (\"what is the discounted sum of rewards from this state?\").","category":"page"},{"location":"problems/metrics.html#DecisionProblems.DecisionMetric","page":"Metrics","title":"DecisionProblems.DecisionMetric","text":"DecisionMetric\n\nA decision metric: an aggregator of outputs of a DecisionSetting, DecisionEnvironment, or similar object. \n\nWhen called with one argument, performs aggregate!.\n\nUnlike most Decisions.jl components they are allowed (and expected) to be mutable and stateful. \n\n\n\n\n\n","category":"type"},{"location":"problems/metrics.html","page":"Metrics","title":"Metrics","text":"DecisionMetrics act as aggregators for the values of random variables, and among other things, they can be provided as the first argument of sample. At each iterate (or once after execution, for a non-dynamic decision network), the metric's aggregate! is called with a NamedTuple of random variable values from the network.","category":"page"},{"location":"problems/metrics.html#DecisionProblems.aggregate!","page":"Metrics","title":"DecisionProblems.aggregate!","text":"aggregate!(::DecisionMetric, values)\n\nAggregate values in the NamedTuple values into the metric.\n\n\n\n\n\n","category":"function"},{"location":"problems/metrics.html","page":"Metrics","title":"Metrics","text":"Unlike most components of Decisions.jl, decision metrics are stateful. (This helps prevent excessive memory usage from computing episode traces). Use output to retrieve the result after aggregation, or reset! to reset the metric object to its initial configuration:","category":"page"},{"location":"problems/metrics.html#DecisionProblems.output","page":"Metrics","title":"DecisionProblems.output","text":"output(::DecisionMetric)\n\nGive the current value of the aggregated metric calculated by the DecisionMetric.\n\n\n\n\n\n","category":"function"},{"location":"problems/metrics.html#DecisionProblems.reset!","page":"Metrics","title":"DecisionProblems.reset!","text":"reset!(::DecisionMetric)\n\nResets the DecisionMetric to a state before aggregating.\n\n\n\n\n\n","category":"function"},{"location":"problems/metrics.html#Provided-decision-metrics","page":"Metrics","title":"Provided decision metrics","text":"","category":"section"},{"location":"problems/metrics.html","page":"Metrics","title":"Metrics","text":"DecisionMetrics are primarily used for consistency and fair comparison: while using a stateful do block for sample is permissible, using a DecisionMetric instead ensures all algorithms which use the same metric follow precisely the same objective definition (even, to some extent, with different decision networks). As such DecisionProblems.jl provides a number of definitive metrics.","category":"page"},{"location":"problems/metrics.html","page":"Metrics","title":"Metrics","text":"todo: Todo\nA significant number of metrics remain to be written. ","category":"page"},{"location":"problems/metrics.html#DecisionProblems.Discounted","page":"Metrics","title":"DecisionProblems.Discounted","text":"Discounted{id} <: DecisionMetric\n\nMetric which aggregates a value labelled id as a discounted summation: every subsequent aggregate! increases the discount and decreases the impact of future calls.\n\nDiscounting is forward-directed; that is, it is assumed that the first call to  aggregate! is the least discounted.\n\n\n\n\n\n","category":"type"},{"location":"problems/metrics.html#DecisionProblems.DiscountedReward","page":"Metrics","title":"DecisionProblems.DiscountedReward","text":"const DiscountedReward\n\nAlias for Discounted{:r}.\n\n\n\n\n\n","category":"type"},{"location":"problems/metrics.html#DecisionProblems.Trace","page":"Metrics","title":"DecisionProblems.Trace","text":"Trace{ids} <: DecisionMetric\n\nMetric which simply aggregates all values labelled in the Tuple ids into Vectors.\n\nIf ids is the empty tuple, aggregates all values passed to it.\n\n\n\n\n\n","category":"type"},{"location":"problems/metrics.html#DecisionProblems.NIters","page":"Metrics","title":"DecisionProblems.NIters","text":"NIters <: DecisionMetric\n\nA metric that simply tracks the number of times it has been aggregated. \n\nMore efficient for computing episode lengths than length(output(t::Trace)).\n\n\n\n\n\n","category":"type"},{"location":"problems/faq.html#FAQ","page":"FAQ","title":"FAQ","text":"","category":"section"},{"location":"problems/faq.html","page":"FAQ","title":"FAQ","text":"todo: Todo\nDocs in progress.","category":"page"},{"location":"problems/faq.html#What's-the-point-of-having-very-simple-\"boilerplate\"-metrics-like-MaxIters?","page":"FAQ","title":"What's the point of having very simple \"boilerplate\" metrics like MaxIters?","text":"","category":"section"},{"location":"networks/conditional_dists.html#Conditional-distributions","page":"Conditional distributions","title":"Conditional distributions","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Decisions.jl provides an interface for conditional distributions (CDs), ConditionalDist, used to implement the nodes of decision networks. Once can draw samples from a conditional distribution, evaluate its PDF, get its support, and so forth, all conditioned on named random variables, so long as the corresponding functions are implemented (which need not be the case).","category":"page"},{"location":"networks/conditional_dists.html#DecisionNetworks.ConditionalDist","page":"Conditional distributions","title":"DecisionNetworks.ConditionalDist","text":"ConditionalDist\n\nA conditional distribution: a stochastic mapping from a set of conditioning variables K to a random variable of type T.\n\n\n\n\n\n","category":"type"},{"location":"networks/conditional_dists.html#The-conditional-distribution-interface","page":"Conditional distributions","title":"The conditional distribution interface","text":"","category":"section"},{"location":"networks/conditional_dists.html#Functions-defined-on-conditional-distributions","page":"Conditional distributions","title":"Functions defined on conditional distributions","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Conditional distributions are subclasses of ConditionalDist{K, T} which implement some or all of the following functions:","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Function Default Description\nsupport TypeSpace{T} Support of a CD, possibly conditioned random variables.\nrand! Base.rand(...) Sample from a CD in place if possible.\npdf exp(logpdf(...)) Give probability [density] of an output value.\nconditions K Tuple of Symbol names of random variables conditioning a CD.\nBase.eltype T Output type of values generated according to a CD.\nfix FixedDist(...) Fix value of a conditioning variable of a CD for a new CD.\nBase.rand none Sample from a CD, conditioned on RVs as keyword arguments.\nlogpdf none Give log-probability [density] of a output value.","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"To be considered valid, all the above functions defined for ConditionalDists must be pure (with the exception of the in-place functions, which may only modify their destination argument.)","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"warning: Warning\nDecisions.jl can't check if your ConditionalDists are pure functions. If they are not,  it's impossible to make accurate guarantees about related Decisions objects, which can result in unexpected or incorrect behavior from solvers.","category":"page"},{"location":"networks/conditional_dists.html#Random-variable-values-are-keyword-arguments","page":"Conditional distributions","title":"Random variable values are keyword arguments","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"In functions that accept them, the values of random variables that condition a ConditionalDist are given as keyword arguments (where the keyword is the name of the random variable). Be aware of these consequences:","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Conditioning variables are orderless, matching their mathematical presentation (i.e., p(x A=a B=b) = p(x  B=b A=a)).\nFunctions like support can be defined for arbitrary combinations of conditioning","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"variables, or none at all. Use rv=missing as the default keyword value in this case and check for presence with ismissing.","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"You cannot dispatch the above functions on conditioning variables.","category":"page"},{"location":"networks/conditional_dists.html#DecisionNetworks.support","page":"Conditional distributions","title":"DecisionNetworks.support","text":"support(cd::ConditionalDist{K, T}; kwargs...)\n\nGive the support Space of the distribution when the conditioning variables K take on the values in kwargs (if it is present), or a superspace containing it.\n\nIf no conditioning variables are provided, give the joint support Space over all conditionings. Optionally, if some, but not all, conditioning variables are provided, the joint support Space over the remaining conditioning variables should be returned.\n\nBy default, returns a TypeSpace{T}.\n\n\n\n\n\n","category":"function"},{"location":"networks/conditional_dists.html#Random.rand!","page":"Conditional distributions","title":"Random.rand!","text":"rand!(rng=default_rng(), cd::ConditionalDist{K, T}, dest::T; kwargs...) where {K, T}\n\nSample from a conditional distribution (in place using dest if possible), with the conditioning variables taking on the values in kwargs.\n\nReturns dest if in-place modification is successful; otherwise, returns a new instance. By default, never modifies in place and defers to rand.\n\n\n\n\n\n","category":"function"},{"location":"networks/conditional_dists.html#DecisionNetworks.pdf","page":"Conditional distributions","title":"DecisionNetworks.pdf","text":"pdf(cd::ConditionalDist, x; kwargs...)\n\nGives the probability or probability density of a random variable distributed according to cd with the value x, given values of conditioning variables in kwargs.\n\nEquivalent to cd(x; kwargs...)\n\n\n\n\n\n","category":"function"},{"location":"networks/conditional_dists.html#DecisionNetworks.conditions","page":"Conditional distributions","title":"DecisionNetworks.conditions","text":"conditions(cd::ConditionalDist)\n\nReport the names of the conditioning variables of cd as a tuple of Symbols.\n\n\n\n\n\nconditions(dn::DecisionGraph, s::Symbol)\nconditions(dn::DecisionNetwork, s::Symbol)\n\nGive the names of the conditioning variables of s in dn (including any indexing variables).\n\n\n\n\n\n","category":"function"},{"location":"networks/conditional_dists.html#Base.eltype-Union{Tuple{ConditionalDist{K, T}}, Tuple{T}, Tuple{K}} where {K, T}","page":"Conditional distributions","title":"Base.eltype","text":"Base.eltype(::ConditionalDist{K, T}) where {K, T}\n\nWhen applied to a ConditionalDist, give T, the type of values produced by the distribution.\n\n\n\n\n\n","category":"method"},{"location":"networks/conditional_dists.html#Base.rand-Tuple{ConditionalDist}","page":"Conditional distributions","title":"Base.rand","text":"rand(rng=default_rng(), cd::ConditionalDist; kwargs...)\n\nSample from a conditional distribution, given values of conditioning variables in kwargs.\n\nEquivalent to cd(; kwargs...).\n\n\n\n\n\n","category":"method"},{"location":"networks/conditional_dists.html#DecisionNetworks.logpdf","page":"Conditional distributions","title":"DecisionNetworks.logpdf","text":"logpdf(cd::ConditionalDist, x; kwargs...)\n\nGives the natural logarithm of the probability or probability density of the random variable distributed according to cd having the value x, given values of conditioning variables in kwargs.\n\n\n\n\n\n","category":"function"},{"location":"networks/conditional_dists.html#DecisionNetworks.fix","page":"Conditional distributions","title":"DecisionNetworks.fix","text":"fix(cd::ConditionalDist; fixed_args...)\n\nFix any number of variables conditioning a distribution to particular values, returning a new conditional distribution conditioned on the variables that remain.\n\nBy default produces a FixedDist.\n\n\n\n\n\n","category":"function"},{"location":"networks/conditional_dists.html#Statistical-syntax","page":"Conditional distributions","title":"Statistical syntax","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"ConditionalDists are callable, and refer to rand (when called with only keyword arguments) and pdf (when called with exactly one argument as well), i.e.","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"my_dist = MyConditionalDist()\nmy_dist(; a, b)   # same as rand(my_dist; a, b)\nmy_dist(x ; a, b) # same as pdf(my_dist, x; a, b)","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"This mimics the statistical syntax x sim p_textrmmy_dist(cdot  a b) and p_textrmmy_dist(x  a b) respectively, with the semicolon replacing the vertical bar.","category":"page"},{"location":"networks/conditional_dists.html#Terminal-states-(and-other-outputs)","page":"Conditional distributions","title":"Terminal states (and other outputs)","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Sometimes a distribution is provided with conditions that represent an exceptional, simulation-halting \"terminal\" case (i.e., a \"terminal state\"). Under these conditions, distributions are expected to return the unique value terminal, which is not included in the distribution support. ","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"The Terminality trait can be used to signal that a distribution in a DN should never produce terminal. ","category":"page"},{"location":"networks/conditional_dists.html#DecisionNetworks.Terminal","page":"Conditional distributions","title":"DecisionNetworks.Terminal","text":"struct Terminal end\n\nType of the unique value representing the output of a decision node as being terminal or otherwise exceptional. \n\n\n\n\n\n","category":"type"},{"location":"networks/conditional_dists.html#DecisionNetworks.terminal","page":"Conditional distributions","title":"DecisionNetworks.terminal","text":"terminal\n\nUnique value representing the output of a decision node as being terminal or otherwise exceptional. The singleton instance of type Terminal.\n\n\n\n\n\n","category":"constant"},{"location":"networks/conditional_dists.html#DecisionNetworks.isterminal","page":"Conditional distributions","title":"DecisionNetworks.isterminal","text":"isterminal(x)\n\nReturn true if and only if x === terminal, and false otherwise, in the style of isnothing.\n\n\n\n\n\n","category":"function"},{"location":"networks/conditional_dists.html#Defining-conditional-distributions","page":"Conditional distributions","title":"Defining conditional distributions","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"There are several ways to define and instantiate ConditionalDists. ","category":"page"},{"location":"networks/conditional_dists.html#Explicit-conditional-distributions","page":"Conditional distributions","title":"Explicit conditional distributions","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Of course, one can simply write a subclass of ConditionalDist:","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"using Random\nstruct MyCD <: ConditionalDist{(:s, :a), Float64}\n    val::Float64\nend\n\nfunction Random.rand(rng, cd::MyCD; s, a)\n    s+a+cd.val\nend\n\nmycd = MyCD(3)\nmycd(; s=1, a=2)","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"todo: Todo\nThe rng argument is required. In the future rng should be moved to a special  keyword argument.","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"This is a generative-only distribution; no PDF is known, which is perfectly valid in Decisions.jl. In general, one can define only the functions of a CD that are known. (Another common case is when the support of a distribution is known, but not a PDF or a generative function - this is all that is known about a decision node in a DN before a decision is actually made. See UndefinedDist.)","category":"page"},{"location":"networks/conditional_dists.html#@ConditionalDist","page":"Conditional distributions","title":"@ConditionalDist","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Fully defining a decision network requires a lot of conditional distributions, and fully specifying them as their own types is tedious, so a macro @ConditionalDist is available.","category":"page"},{"location":"networks/conditional_dists.html#DecisionNetworks.@ConditionalDist","page":"Conditional distributions","title":"DecisionNetworks.@ConditionalDist","text":"@ConditionalDist\n\nGenerate an anonymous conditional distribution definition from a set of functions.\n\nThe functions can be any of those in the ConditionalDist interface and must be named accordingly, with the ::ConditionalDist argument omitted. They can be defined with the function keyword or in the compact style. The names of conditioning variables are automatically inferred from the names of keyword arguments.\n\nThe rng argument is mandatory in functions that use it.\n\n\n\n\n\n","category":"macro"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Technically, @ConditionalDist defines an anonymous conditional distribution which is a unique subtype of ConditionalDist.","category":"page"},{"location":"networks/conditional_dists.html#DecisionNetworks.AnonymousDist","page":"Conditional distributions","title":"DecisionNetworks.AnonymousDist","text":"AnonymousDist\n\nAn anonymous distribution: one defined with @ConditionalDist. \n\nIt carries its implementation as higher order functions, so every AnonymousDist has a unique type (not unlike anonymous functions).\n\n\n\n\n\n","category":"type"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Anonymous conditional distributions can be defined inside functions and other places where structs cannot usually be defined. They can also include closures over external variables. This substantially condenses CD definitions - for instance, the previous example can be rewritten as:","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"    MyCD(val) = @ConditionalDist Float64 begin\n        rand(rng; s, a) = s+a+val\n    end\n    mycd = MyCD(3)\n    mycd(; s=1, a=2)","category":"page"},{"location":"networks/conditional_dists.html#Structural-conditional-distributions","page":"Conditional distributions","title":"Structural conditional distributions","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"DecisionNetworks.jl provides a few very basic distributions explicitly which have important structural meaning:","category":"page"},{"location":"networks/conditional_dists.html#DecisionNetworks.UndefinedDist","page":"Conditional distributions","title":"DecisionNetworks.UndefinedDist","text":"UndefinedDist\n\nA distribution that has no PDF or sampling defined. Only its support is known.\n\n\n\n\n\n","category":"type"},{"location":"networks/conditional_dists.html#DecisionNetworks.CompoundDist","page":"Conditional distributions","title":"DecisionNetworks.CompoundDist","text":"CompoundDist{K, T, Ki} <: ConditionalDist{K, T}\n\nA distribution which implements P(⋅ | idx, ...) using a Tuple of P(⋅ | ...) distributions (where idx maps into that tuple).\n\nUseful for merging behavior of multiple agents into a single distribution.\n\n\n\n\n\n","category":"type"},{"location":"networks/conditional_dists.html#DecisionNetworks.CollectDist","page":"Conditional distributions","title":"DecisionNetworks.CollectDist","text":"CollectDist <: ConditionalDist\n\nA deterministic conditional dist which simply stacks its inputs as a Tuple. \n\n\n\n\n\n","category":"type"},{"location":"networks/conditional_dists.html#DecisionNetworks.FixedDist","page":"Conditional distributions","title":"DecisionNetworks.FixedDist","text":"FixedDist <: ConditionalDist\n\nA conditional distribution that wraps another, maintaining values of fixed variables; also, the default output of fix.\n\nForwards most standard ConditionalDist functions to its underlying distribution, conditioned on the inputs and the fixed variables.\n\n\n\n\n\n","category":"type"},{"location":"networks/conditional_dists.html#DecisionNetworks.UniformDist","page":"Conditional distributions","title":"DecisionNetworks.UniformDist","text":"UniformDist{K, T} <: ConditionalDist{K, T}\n\nA discrete uniform distribution: selects elements from its finite support with equal probability.\n\n\n\n\n\n","category":"type"},{"location":"networks/conditional_dists.html#Conditional-distributions-from-Distributions.jl","page":"Conditional distributions","title":"Conditional distributions from Distributions.jl","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"todo: Todo\nNot currently implemented.","category":"page"},{"location":"networks/conditional_dists.html#Objects-that-convert-to-ConditionalDists","page":"Conditional distributions","title":"Objects that convert to ConditionalDists","text":"","category":"section"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Some basic objects can be interpreted as ConditionalDists with convert:","category":"page"},{"location":"networks/conditional_dists.html","page":"Conditional distributions","title":"Conditional distributions","text":"Functions are interpreted as sample generators and form generative-only distributions. The conditioning variable names and the output type must be specified by the type parameters {K, T} on the target ConditionalDist{K, T}.\nSpaces are interpreted as UndefinedDists which return the given space their unconditioned support. Only the conditioning variable names {K} on the target ConditionalDist{K} need be defined; the output type T is inferred from the space.","category":"page"},{"location":"networks/decision_graphs.html#Decision-graphs","page":"Decision graphs","title":"Decision graphs","text":"","category":"section"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"Decision graphs are Types of decision networks. More specifically, they are directed acyclic graphs without any implementations for the conditional distributions backing the nodes. Decisions.jl uses decision graphs to compile optimized code for any particular kind of decision network. Additionally, DecisionNetworks.jl allows for modifying these decision graphs to define new problem frameworks. As such, decision graphs are imbued with significantly more functionality than Julia types in general.","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"One can extract the decision graph from a decision network using graph, or just plain old typeof.","category":"page"},{"location":"networks/decision_graphs.html#DecisionNetworks.graph","page":"Decision graphs","title":"DecisionNetworks.graph","text":"graph(dn::DecisionNetwork)\n\nGive the decision graph for decision network dn.\n\n\n\n\n\ngraph(::DecisionProblem{M, DG})\n\nWhen applied to a DecisionProblem, give the DecisionGraph for its underlying model.\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html#Structure-of-decision-graphs","page":"Decision graphs","title":"Structure of decision graphs","text":"","category":"section"},{"location":"networks/decision_graphs.html#Random-variable-groups","page":"Decision graphs","title":"Random variable groups","text":"","category":"section"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"Every node of a decision graph represents a random variable, or more specifically, a plate of random elements (which is itself a random variable). Plates have indexing variables: special named variables treated like random variables which indicate which element within a plate is to be considered. Since indexing variables are treated like random variables, instead of writing p(cdot  ) for all i (where i is an indexing variable), we need only write p(cdot  i ). ","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"Plates can be jointly sampled across their elements, independently sampled, or joint on some axes and independent on others. ","category":"page"},{"location":"networks/decision_graphs.html#DecisionNetworks.Plate","page":"Decision graphs","title":"DecisionNetworks.Plate","text":"abstract type Plate <: RVGroup\n\nAbstract base type for sampleable groups of random variables, specified over given axes, which is itself a random variable.\n\nThere can be various independence relationships between the nodes in the group. See Indep, Joint, and JointAndIndep.\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html#DecisionNetworks.Joint","page":"Decision graphs","title":"DecisionNetworks.Joint","text":"Joint\n\nA group of random variables that are jointly related to each other (that is, are not independent).\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html#DecisionNetworks.Indep","page":"Decision graphs","title":"DecisionNetworks.Indep","text":"Indep\n\nA group of random variables that are all (conditionally) independent.\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html#DecisionNetworks.JointAndIndep","page":"Decision graphs","title":"DecisionNetworks.JointAndIndep","text":"JointAndIndep\n\nA group of random variables that are jointly related on some axes and independently related on the rest.\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"Each input into a plate is a group of random variables from another plate, which we call conditioning groups. ConditioningGroups can condition every element of a Plate (many-to-many), or only those elements at corresponding indices (one-to-one).","category":"page"},{"location":"networks/decision_graphs.html#DecisionNetworks.ConditioningGroup","page":"Decision graphs","title":"DecisionNetworks.ConditioningGroup","text":"abstract type Condition <: RVGroup\n\nA group of random variables specified as conditioning variables on another random variable. Cannot be sampled on its own. \n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html#DecisionNetworks.Dense","page":"Decision graphs","title":"DecisionNetworks.Dense","text":"Dense\n\nA group of conditioning variables that condition every random variable in any group they condition.\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html#DecisionNetworks.Parallel","page":"Decision graphs","title":"DecisionNetworks.Parallel","text":"Parallel\n\nA group of conditioning variables that condition only random variables at matching indices in any group they condition (which need not be every index in either group).\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"Plates and conditioning groups know the name of the random variable they represent, as well as the names of the indexing variables that index into them:","category":"page"},{"location":"networks/decision_graphs.html#DecisionNetworks.name","page":"Decision graphs","title":"DecisionNetworks.name","text":"name(::RVGroup)\n\nGive the name of a group of random variables.\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html#DecisionNetworks.indices","page":"Decision graphs","title":"DecisionNetworks.indices","text":"indices(::RVGroup)\n\nGive the names of the indexing variables for a group of random variables.\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html#Components-of-decision-graphs","page":"Decision graphs","title":"Components of decision graphs","text":"","category":"section"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"Decision graphs are represented with three components: ","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"An inputs => output definition for each node, \nMappings from current-iterate to next-iterate nodes (for a dynamic decision network), and\nThe range of variables that index into each plate.","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"They can all be queried of both DecisionNetworks and Type{<:DecisionNetwork}s.","category":"page"},{"location":"networks/decision_graphs.html#DecisionNetworks.nodes","page":"Decision graphs","title":"DecisionNetworks.nodes","text":"nodes(::DecisionGraph)\nnodes(::DecisionNetwork)\n\nGive the node definitions of a decision network.\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html#DecisionNetworks.dynamic_pairs","page":"Decision graphs","title":"DecisionNetworks.dynamic_pairs","text":"dynamic_pairs(::DecisionGraph)\ndynamic_pairs(::DecisionNetwork)\n\nGive the dynamic pairs for a decision network, mapping current to next iterate node names.\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html#DecisionNetworks.ranges","page":"Decision graphs","title":"DecisionNetworks.ranges","text":"ranges(::DecisionGraph)\nranges(::DecisionNetwork)\n\nGive a NamedTuple defining the ranges over which plates in a decision network are defined: each key is a name of an indexing variables, and each value is the plate size along that index.\n\nIf given a DecisionGraph where the range parameter is not specified, returns nothing.\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"A number of convenience functions are also provided to make navigating DecisionGraphs slightly easier:","category":"page"},{"location":"networks/decision_graphs.html#DecisionNetworks.node_names","page":"Decision graphs","title":"DecisionNetworks.node_names","text":"node_names(::DecisionGraph)\nnode_names(::DecisionNetwork)\n\nGive the names (as Symbols) of all random variables in a decision network.\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html#DecisionNetworks.children","page":"Decision graphs","title":"DecisionNetworks.children","text":"children(dn::DecisionGraph, s::Symbol)\nchildren(dn::DecisionNetwork, s::Symbol)\n\nGive the names of all nodes in dn that are conditioned on s.\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html#DecisionNetworks.next","page":"Decision graphs","title":"DecisionNetworks.next","text":"next(dn::DecisionNetwork, node)\nnext(dn::DecisionGraph, node)\n\nGive the next-step counterpart of node in a [type of] decision network dn.\n\ndn must be a dynamic decision network.\n\nExamples\n\njulia> next(MDP_DN, :s)\n:sp\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html#DecisionNetworks.prev","page":"Decision graphs","title":"DecisionNetworks.prev","text":"prev(dn::DecisionNetwork, node)\nprev(dn::DecisionGraph, node)\n\nGive the previous-step counterpart of node in a [type of] decision network dn.\n\ndn must be a dynamic decision network.\n\nExamples\n\njulia> prev(MDP_DN, :sp)\n:s\n\n\n\n\n\n","category":"function"},{"location":"networks/decision_graphs.html#Defining-decision-graphs","page":"Decision graphs","title":"Defining decision graphs","text":"","category":"section"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"DecisionNetworks.jl provides names for some of the most commonly used decision networks, like those that represent MDPs and POMDPs. However, if you're using this package chances are you'd like to define a much wider set of problems and networks based on concepts like multiagency, semi-Markovness, decentralization, and correlation. While there are obviously too many such extensions to name, Decisions.jl provides first-class support for any network once its decision graph has been defined.","category":"page"},{"location":"networks/decision_graphs.html#Standard-Markov-family-networks","page":"Decision graphs","title":"Standard Markov family networks","text":"","category":"section"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"Members of certain families of decision networks can be specified from a limited set of traits. In particular, the family containing most Markov-style networks - and therefore the vast majority of decision problems used today - can be defined using only six nodes and two inputs:","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"s: Current state\nm: Current memory\nsp: Successor state; that is, state-prime. The distribution that implements it is often called the transition. Dynamically paired with s.\nmp: Successor memory; that is, memory-prime (a decision node).  \na: Action (a decision node).\nr: Reward\no: Observation\nτ: Sojourn time (for semi-Markov models)","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"There may also be up to two indexing variables present:","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"i: Index over agents.\nj: Index over multiple rewards.","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"This the standard Markov family. Due to their ubiquity, Decisions.jl provides a shorthand for defining these types of networks based on the relevant traits.","category":"page"},{"location":"networks/decision_graphs.html#DecisionNetworks.@markov_alias","page":"Decision graphs","title":"DecisionNetworks.@markov_alias","text":"@markov_alias(name, traits)\n\nBuild a type alias and constructor for a standard Markov decision network with the given traits.\n\ntraits is expected to be a MarkovAmbiguousTraits. If any traits are ambiguous, a Union over the possible decision graphs is defined. Otherwise, a single decision graph is defined.\n\n\n\n\n\n","category":"macro"},{"location":"networks/decision_graphs.html#DecisionNetworks.MarkovAmbiguousTraits","page":"Decision graphs","title":"DecisionNetworks.MarkovAmbiguousTraits","text":"MarkovAmbiguousTraits\nMarkovAmbiguousTraits(pairs...)\n\nA collection of traits for a standard Markov family problem.\n\npairs are Trait => TraitValue mappings; e.g., Multiagency => NoAgent(). Any traits that are not defined default using markov_default.\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html#Named-network-types","page":"Decision graphs","title":"Named network types","text":"","category":"section"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"A few exceptionally important decision graphs have aliases provided by Decisions.jl. They are all members of the standard Markov family.","category":"page"},{"location":"networks/decision_graphs.html#DecisionNetworks.MDP_DN","page":"Decision graphs","title":"DecisionNetworks.MDP_DN","text":"MDP_DN\n\nCanonical decision network underlying a Markov decision process.\n\nAssumes the memory node is not present and the reward is conditioned on (:s, :a, :sp).\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html#DecisionNetworks.POMDP_DN","page":"Decision graphs","title":"DecisionNetworks.POMDP_DN","text":"POMDP_DN\n\nCanonical decision network underlying a partially observable Markov decision process.\n\nAssumes the memory node is present and the reward is conditioned on (:s, :a, :sp).\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html#DecisionNetworks.MG_DN","page":"Decision graphs","title":"DecisionNetworks.MG_DN","text":"MG_DN\n\nCanonical decision network underlying a Markov game.\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html#DecisionNetworks.DecPOMDP_DN","page":"Decision graphs","title":"DecisionNetworks.DecPOMDP_DN","text":"DecPOMDP_DN\n\nCanonical decision network underlying a decentralized partially observable Markov decision process.\n\n\n\n\n\n","category":"type"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"You can use transformations to transform these networks into your specific target.","category":"page"},{"location":"networks/decision_graphs.html#Defining-networks-by-hand","page":"Decision graphs","title":"Defining networks by hand","text":"","category":"section"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"If the type of decision network you'd like to work with isn't a standard Markov problem, and can't easily be transformed from one, you may want to define it by hand.","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"A new type of decision network can be defined with the DecisionGraph constructor:","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"nodes is a list of pairs, each one mapping node inputs (as ConditioningGroups) to an output (as a Plate). \ndynamic_pairs is a NamedTuple mapping current-iterate to future-iterate node names.\nranges is a NamedTuple mapping indexing variable names to lengths.","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"For instance, we might want to define a mixed observability Markov decision problem with a memory node. MOMDP networks aren't standard Markov networks due to the factored state, so we should just define them manually:","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"const MOMDP = DecisionGraph(\n  [ # Six regular nodes (:xp, :yp, :r, :o, :mp, :a)\n    (Dense(:x), Dense(:y), Dense(:a)) => Joint(:xp),\n    (Dense(:x), Dense(:y), Dense(:a), Dense(:xp)) => Joint(:yp),\n    (Dense(:x), Dense(:y), Dense(:a)) => Joint(:r),\n    (Dense(:x), Dense(:y), Dense(:a)) => Joint(:o),\n    (Dense(:x), Dense(:o), Dense(:a), Dense(:m)) => Joint(:mp),\n    (Dense(:m),) => Joint(:a),\n  ],\n  (; # Three dynamic nodes (:x, :y, :m)\n    :x => :xp,\n    :y => :yp,\n    :m => :mp\n  ),\n  (;) # No ranges\n)\n\n# Create a MOMDP with no node implementations at all\nmy_empty_MOMDP = MOMDP(;)","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"To visually double-check that your new decision graph is correct, use dnplot (though be aware that networks with many nodes may render poorly):","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"dnplot(MOMDP)","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"tip: Tip\nFor performance reasons, when defining a new decision graph for use later, it's recommended to mark it as const.","category":"page"},{"location":"networks/decision_graphs.html","page":"Decision graphs","title":"Decision graphs","text":"warning: Warning\nUse the DecisionGraph constructor to get a Type{<:DecisionNetwork} rather than using DecisionNetwork{...} directly. This ensures that nodes and other parameters of the decision graph can have enforced structures (for instance, order invariance on inputs) to prevent ambuguity.","category":"page"},{"location":"networks/performance.html#Advanced:-Performance","page":"Advanced: Performance","title":"Advanced: Performance","text":"","category":"section"},{"location":"networks/performance.html#Performance-tips-for-ConditionalDists","page":"Advanced: Performance","title":"Performance tips for ConditionalDists","text":"","category":"section"},{"location":"networks/performance.html","page":"Advanced: Performance","title":"Advanced: Performance","text":"todo: Todo\nNeed to write some tests to confirm this behavior.","category":"page"},{"location":"networks/performance.html","page":"Advanced: Performance","title":"Advanced: Performance","text":"Sampling a distribution often occurs in a very tight loop, making performance within the distribution very important. Aside from the general performance tips for Julia code, here are a few specific ways to optimize code using ConditionalDists:","category":"page"},{"location":"networks/performance.html#Prefer-rand!-over-rand","page":"Advanced: Performance","title":"Prefer rand! over rand","text":"","category":"section"},{"location":"networks/performance.html","page":"Advanced: Performance","title":"Advanced: Performance","text":"When it's possible to sample a distribution in place, doing so can reduce unnecessary allocations and therefore speed up your code.","category":"page"},{"location":"networks/performance.html#Prefer-logpdf-over-pdf","page":"Advanced: Performance","title":"Prefer logpdf over pdf","text":"","category":"section"},{"location":"networks/performance.html","page":"Advanced: Performance","title":"Advanced: Performance","text":"For the usual numerical reasons, it's generally preferable to use logpdf where possible; pdf simply defaults to exp(logpdf(...)). When it really is more efficient to calculate the PDF, pdf (and logpdf) can be specialized to change this behavior.","category":"page"},{"location":"networks/performance.html#Provide-a-concrete-sample-type","page":"Advanced: Performance","title":"Provide a concrete sample type","text":"","category":"section"},{"location":"networks/performance.html","page":"Advanced: Performance","title":"Advanced: Performance","text":"If the eltype of a ConditionalDist is concrete, it is possible to generate very performant, potentially stack-allocated sampling code. Using Any or other abstract types will work and can be useful for prototyping, but comes at a performance cost. ","category":"page"},{"location":"networks/performance.html#Use-@ConditionalDist-wisely","page":"Advanced: Performance","title":"Use @ConditionalDist wisely","text":"","category":"section"},{"location":"networks/performance.html","page":"Advanced: Performance","title":"Advanced: Performance","text":"When using @ConditionalDist, be aware that there may be subtle performance impacts, particularly with regards to closures.  If in doubt in a performance-critical setting, use an explicitly defined distribution.","category":"page"},{"location":"networks/spaces.html#Spaces","page":"Spaces","title":"Spaces","text":"","category":"section"},{"location":"networks/spaces.html","page":"Spaces","title":"Spaces","text":"Spaces represent abstract sets of values represented by a shared Type. They are used to define supports for ConditionalDists and are in general handy to query for many decision-making algorithms. ","category":"page"},{"location":"networks/spaces.html#DecisionNetworks.Space","page":"Spaces","title":"DecisionNetworks.Space","text":"abstract type Space{T}\n\nAbstract base representation for spaces, possibly infinite sets of instances all backed by type T.\n\n\n\n\n\n","category":"type"},{"location":"networks/spaces.html#The-space-interface","page":"Spaces","title":"The space interface","text":"","category":"section"},{"location":"networks/spaces.html","page":"Spaces","title":"Spaces","text":"Spaces are subtypes of Space{T}. The space interface is related to the iteration interface, but not all spaces can be iterated (some are continuous). ","category":"page"},{"location":"networks/spaces.html#Mandatory-functions","page":"Spaces","title":"Mandatory functions","text":"","category":"section"},{"location":"networks/spaces.html","page":"Spaces","title":"Spaces","text":"Base.in(el, s::Space): Give whether item el is in space s.\nBase.eltype(::Space{T}): Gives the backing type of the space. Defaults to T.","category":"page"},{"location":"networks/spaces.html#Optional-functions","page":"Spaces","title":"Optional functions","text":"","category":"section"},{"location":"networks/spaces.html","page":"Spaces","title":"Spaces","text":"Base.zero(::Space): Provide the additive identity element, assuming + is defined over the space.\nBase.one(::Space): Provide the multiplicative identity element, assuming * is defined over the space.\nBase.length(::Space): Give the cardinality of a space, if it is finite. Otherwise (and by default), return Inf. \nBase.iterate(::Space [, state]): For a discrete state, provide iteration support (see (Iteration)[https://docs.julialang.org/en/v1/manual/interfaces/#man-interface-iteration])","category":"page"},{"location":"networks/spaces.html#Predefined-spaces","page":"Spaces","title":"Predefined spaces","text":"","category":"section"},{"location":"networks/spaces.html","page":"Spaces","title":"Spaces","text":"Some handy Space types are named by Decisions.jl: ","category":"page"},{"location":"networks/spaces.html#DecisionNetworks.FiniteSpace","page":"Spaces","title":"DecisionNetworks.FiniteSpace","text":"FiniteSpace{T, N} <: Space{T}\n\nRepresentation of a finite set backed by type T.\n\nSupports iteration.\n\n\n\n\n\n","category":"type"},{"location":"networks/spaces.html#DecisionNetworks.RangeSpace","page":"Spaces","title":"DecisionNetworks.RangeSpace","text":"RangeSpace{T} <: Space{T}\n\nSpace representing range of set elements backed by type T from lb to ub, inclusive (according to ≤).\n\n\n\n\n\n","category":"type"},{"location":"networks/spaces.html#DecisionNetworks.TypeSpace","page":"Spaces","title":"DecisionNetworks.TypeSpace","text":"TypeSpace{T} <: Space{T}\n\nSpace that is exactly coextensive with its backing type, T: that is, any instance of T is an element of T.\n\nTypeSpace{T} can also be used (with caution) to represent proper subsets of T when the exact extent of the subset is unknown or difficult to calculate.  \n\n\n\n\n\n","category":"type"},{"location":"networks/spaces.html#DecisionNetworks.SingletonSpace","page":"Spaces","title":"DecisionNetworks.SingletonSpace","text":"SingletonSpace{T} <: Space{T}\n\nSpace that consists of exactly one element el.\n\n\n\n\n\n","category":"type"},{"location":"networks/visualization.html#Visualization","page":"Visualization","title":"Visualization","text":"","category":"section"},{"location":"networks/visualization.html#Base.show","page":"Visualization","title":"Base.show","text":"","category":"section"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"Decision networks are pretty-printed to show the constituent random/indexing variables and their conditions:","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"DecPOMDP_DN((; i = 4); sp = (; a, s) -> \"successor state\")","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"Ordinary random variables are shown with a conditioning bar. If there is a corresponding conditional distribution implemented in the network, the type of the distribution is shown. Past-iterate / future-iterate random variable pairs are denoted with =>, and indexing variables are shown denoted with ∈.","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"Plates which are independently sampled over one or more indices are shown with those indices in array notation. Similarly, Parallel conditionings are also shown with their indices. For instance, here, we see that the actions a for each player i are independently sampled, using the corresponding player's memory from m.","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"Decision graphs are not similarly pretty-printed, for reasons related to Julia internals.","category":"page"},{"location":"networks/visualization.html#Plots.jl","page":"Visualization","title":"Plots.jl","text":"","category":"section"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"Use dnplot to visualize a DecisionNetwork or a DecisionGraph into a Plots.jl plot.","category":"page"},{"location":"networks/visualization.html#DecisionNetworks.dnplot","page":"Visualization","title":"DecisionNetworks.dnplot","text":"dnplot(d::DecisionGraph; kws...)\ndnplot(d::DecisionNetwork; kws...)\n\nVisualize the decision network or decision graph `d` via Plots.jl.\n\nKeywords are passed into `graphplot`; see its documentation for details.\n\n\n\n\n\n","category":"function"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"This can be very useful to debug the specific definition of particular decision graphs. For instance, we can query the structure of a particular Dec-POMDP:","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"my_decpomdp = DecPOMDP_DN((; i=4); \n    o = (; s, a, i) -> \"obs\", \n    r = (; s, a, sp) -> \"rwd\",\n    sp = (; s, a) -> \"successor state\"\n)\n\ndnplot(my_decpomdp)","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"As before, parallel edges and independently sampled nodes are denoted with array notation.","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"sp and mp are the next-iterate names for s and m (according to dynamic_pairs). As such, s and m are always identities of last-iterate sp and mp, which is represented with a white (rather than gray) infill in those nodes. ","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"Decisions.jl typically makes no innate distinction between action, output, and chance nodes, but for purposes of visualization the following definitions are used:","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"Action nodes (squares) are nodes without an implemented conditional distribution.\nOutput nodes (diamonds) are leaf nodes.\nChance nodes (circles) are all other nodes.","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"We can also query the structure of Dec-POMDPs in general (that is, the decision graph DecPOMDP_DN):","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"dnplot(DecPOMDP_DN)","category":"page"},{"location":"networks/visualization.html","page":"Visualization","title":"Visualization","text":"Since only DecisionNetworks carry node implementations, without which it is impossible to distinguish between action and chance nodes, all nodes in DecisionGraphs are rendered as hexagons.","category":"page"},{"location":"networks/traits.html#Traits","page":"Traits","title":"Traits","text":"","category":"section"},{"location":"networks/traits.html","page":"Traits","title":"Traits","text":"Decisions.jl provides a variety of named traits on DecisionNetworks, ConditionalDists, and other objects in the package. They serve as hints to algorithms as well as the package itself.","category":"page"},{"location":"networks/traits.html","page":"Traits","title":"Traits","text":"This page provides the technical docs for each trait.","category":"page"},{"location":"networks/traits.html#DecisionNetworks.DecisionsTrait","page":"Traits","title":"DecisionNetworks.DecisionsTrait","text":"abstract type DecisionsTrait\n\nAbstract base trait type for all traits used in Decisions.jl.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Traits-on-decision-networks","page":"Traits","title":"Traits on decision networks","text":"","category":"section"},{"location":"networks/traits.html#Sequentiality","page":"Traits","title":"Sequentiality","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.Sequentiality","page":"Traits","title":"DecisionNetworks.Sequentiality","text":"abstract type Sequentiality <: DecisionsTrait\nSequentiality(::DecisionNetwork)\n\nAbstract trait type denoting whether agents act simultaneously or sequentially.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Sequential","page":"Traits","title":"DecisionNetworks.Sequential","text":"Sequential <: Sequentiality\n\nTrait indicating agents act sequentially (meaning each agent controls one or more independent decision nodes).\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Simultaneous","page":"Traits","title":"DecisionNetworks.Simultaneous","text":"Simultaneous <: Sequentiality\n\nTrait indicating agents act simultaneously (meaning agents implement different indices of the same decision node(s)).\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Partial-observability-/-information-perfection","page":"Traits","title":"Partial observability / information perfection","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.Observability","page":"Traits","title":"DecisionNetworks.Observability","text":"abstract type Observability <: DecisionsTrait\nObservability(::DecisionNetwork)\n\nAbstract trait type indicating whether input to decision nodes passed to an agent or agents is \"full,\" in that it is at least as informative as knowing the values of its predecessors.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.FullyObservable","page":"Traits","title":"DecisionNetworks.FullyObservable","text":"FullyObservable <: Observability\n\nTrait indicating decision nodes receive perfect / full information.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.PartiallyObservable","page":"Traits","title":"DecisionNetworks.PartiallyObservable","text":"PartiallyObservable <: Observability\n\nTrait indicating decision nodes do not receive perfect / full information.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Number-of-agents","page":"Traits","title":"Number of agents","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.Multiagency","page":"Traits","title":"DecisionNetworks.Multiagency","text":"abstract type Multiagency <: DecisionsTrait\nMultiagency(::DecisionNetwork)\n\nAbstract trait type denoting the number of agents, if any, in a problem. \n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.NoAgent","page":"Traits","title":"DecisionNetworks.NoAgent","text":"struct NoAgents <: Multiagency\n\nTrait denoting a network supports no agents (implying no decision nodes).\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.SingleAgent","page":"Traits","title":"DecisionNetworks.SingleAgent","text":"struct SingleAgent <: Multiagency\n\nTrait denoting presence of exactly one agent. \n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.MultiAgent","page":"Traits","title":"DecisionNetworks.MultiAgent","text":"abstract type MultiAgent <: Multiagency\n\nAbstract trait type denoting a network supports multiple agents.\n\nThe exact number of agents may (with DefiniteAgents) or may not (with IndefiniteAgents) be specified.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.DefiniteAgents","page":"Traits","title":"DecisionNetworks.DefiniteAgents","text":"abstract type DefiniteAgents{N} <: MultiAgent\n\nTrait denoting support for exactly N agents.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.IndefiniteAgents","page":"Traits","title":"DecisionNetworks.IndefiniteAgents","text":"abstract type DefiniteAgents{N} <: MultiAgent\n\nTrait denoting support for some number of agents, which is not known ahead of time.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Agent-cooperation","page":"Traits","title":"Agent cooperation","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.Cooperation","page":"Traits","title":"DecisionNetworks.Cooperation","text":"abstract type Cooperation <: DecisionsTrait\nCooperation(::DecisionNetwork)\n\nAbstract trait indiating the extent to which a decision network implies cooperative agents.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Cooperative","page":"Traits","title":"DecisionNetworks.Cooperative","text":"Cooperative <: Cooperation\n\nTrait indicating agents are implied to cooperate or receive a benefit from cooperating.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Competitive","page":"Traits","title":"DecisionNetworks.Competitive","text":"Competitive <: Cooperation\n\nTrait indicating agents are implied to compete or receive a benefit from competing. \n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Individual","page":"Traits","title":"DecisionNetworks.Individual","text":"Individual <: Cooperation\n\nTrait indicating agents are implied to act independently, neither cooperating nor competing.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Agent-memory","page":"Traits","title":"Agent memory","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.MemoryPresence","page":"Traits","title":"DecisionNetworks.MemoryPresence","text":"abstract type MemoryPresence <: DecisionsTrait\nMemoryPresence(::DecisionNetwork)\n\nAbstract trait indicating whether iterates of a dynamic decision network are accrued in an agent-defined memory.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.MemoryPresent","page":"Traits","title":"DecisionNetworks.MemoryPresent","text":"MemoryPresent <: MemoryPresence\n\nAbstract trait indicating iterates of a dynamic decision network are accrued in an agent-defined memory.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.MemoryAbsent","page":"Traits","title":"DecisionNetworks.MemoryAbsent","text":"MemoryAbsent <: MemoryPresence\n\nAbstract trait indicating no accrual of information from iterate to iterate of a dynamic decision network in any agent-defined memory.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Reward-presence-and-style","page":"Traits","title":"Reward presence and style","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.RewardStyle","page":"Traits","title":"DecisionNetworks.RewardStyle","text":"abstract type RewardStyle{ids} <: DecisionsTrait\nRewardStyle(::DecisionNetwork)\n\nAbstract trait indicating whether a decision network has a node analogous to a reward node: a node no others are conditioned on, typically for use in an objective. If so, indicates whether it represents a single or multiple reward, and the other nodes ids it is conditioned on.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.NoReward","page":"Traits","title":"DecisionNetworks.NoReward","text":"struct NoReward <: RewardStyle{()}\n\nTrait indicating a decision network has no node analogous to a \"reward\" node.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.SingleReward","page":"Traits","title":"DecisionNetworks.SingleReward","text":"SingleReward{ids} <: RewardStyle{ids}\n\nTrait indicating a decision network has a \"reward\" node producing a single value, which is conditioned on the nodes ids.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.MultipleRewards","page":"Traits","title":"DecisionNetworks.MultipleRewards","text":"MultipleRewards{ids} <: RewardStyle{ids}\n\nAbstract trait indicating a decision network has a \"reward\" node producing multiple values, which is conditioned on the nodes ids.\n\nThe number of values produced can be known (DefiniteRewards) or unknown (IndefiniteRewards).\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.DefiniteRewards","page":"Traits","title":"DecisionNetworks.DefiniteRewards","text":"DefiniteRewards{N, ids} <: MultipleRewards{ids}\n\nTrait indicating a decision network has a \"reward\" node conditioned on ids which produces exactly N values (that is, it is a plate of size N).\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.IndefiniteRewards","page":"Traits","title":"DecisionNetworks.IndefiniteRewards","text":"IndefiniteRewards <: MultipleRewards{ids}\n\nTrait indicating a decision network has a \"reward\" node conditioned on ids which is a plate of unknown size.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Agent-centralization","page":"Traits","title":"Agent centralization","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.Centralization","page":"Traits","title":"DecisionNetworks.Centralization","text":"Centralization <: DecisionsTrait\nCentralization(::DecisionNetwork)\n\nAbstract trait indicating whether agents receive the same input or not.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Centralized","page":"Traits","title":"DecisionNetworks.Centralized","text":"Centralized <: Centralization\n\nTrait indicating agents receive the same input.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Decentralized","page":"Traits","title":"DecisionNetworks.Decentralized","text":"Decentralized <: Centralization\n\nTrait indicating agents do not receive the same input.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Statefulness-and-state-structure","page":"Traits","title":"Statefulness and state structure","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.Statefulness","page":"Traits","title":"DecisionNetworks.Statefulness","text":"abstract type Statefulness <: DecisionsTrait\nStatefulness(::DecisionNetwork)\n\nAbstract trait indicating whether a \"state\" / \"state update\" node is present, and if so, how it is structured.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Stateful","page":"Traits","title":"DecisionNetworks.Stateful","text":"Stateful <: Statefulness\n\nTrait indicating that a decision network has a \"state\" / \"state update\" node.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Stateless","page":"Traits","title":"DecisionNetworks.Stateless","text":"Stateless <: Statefulness\n\nTrait indicating that a decision network has no \"state\" / \"state update\" node.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.AgentFactored","page":"Traits","title":"DecisionNetworks.AgentFactored","text":"AgentFactored <: Statefulness\n\nTrait indicating that a decision network has a \"state\" / \"state update\" node, and it is a plate with an agent-index axis.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Semi-Markovianness-and-step-style","page":"Traits","title":"Semi-Markovianness and step style","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.TimestepStyle","page":"Traits","title":"DecisionNetworks.TimestepStyle","text":"abstract type TimestepStyle <: DecisionsTrait\nTimestepStyle(::DecisionNetwork)\n\nAbstract trait indicating the time interpretation of each iterate of a dynamic decision network. \n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.SemiMarkov","page":"Traits","title":"DecisionNetworks.SemiMarkov","text":"SemiMarkov <: TimestepStyle\n\nTrait indicating a dynamic decision network is semi-Markov: the sojourn time from iteration to iteration is given by a node in the network.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.FixedTimestep","page":"Traits","title":"DecisionNetworks.FixedTimestep","text":"FixedTimestep <: TimestepStyle\n\nTrait indicating iterates in a dynamic decision network are equal, fixed timesteps with no semi-Markov considerations.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Agent-correlation","page":"Traits","title":"Agent correlation","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.AgentCorrelation","page":"Traits","title":"DecisionNetworks.AgentCorrelation","text":"abstract type AgentCorrelation <: DecisionsTrait\nAgentCorrelation(::DecisionNetwork)\n\nAbstract trait indicating whether decision nodes are sampled jointly or independently across agents.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Correlated","page":"Traits","title":"DecisionNetworks.Correlated","text":"Correlated <: AgentCorrelation\n\nTrait indicating all decision nodes are sampled jointly across agents.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Uncorrelated","page":"Traits","title":"DecisionNetworks.Uncorrelated","text":"Uncorrelated <: AgentCorrelation\n\nTrait indicating all decision nodes are sampled independently across agents.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Traits-on-random-variables","page":"Traits","title":"Traits on random variables","text":"","category":"section"},{"location":"networks/traits.html","page":"Traits","title":"Traits","text":"RVGroups can accept traits, which are primarily used as hints to sample and other such functions for optimal performance.","category":"page"},{"location":"networks/traits.html","page":"Traits","title":"Traits","text":"Due to their internal role they are not exported by default.","category":"page"},{"location":"networks/traits.html#Terminality","page":"Traits","title":"Terminality","text":"","category":"section"},{"location":"networks/traits.html#DecisionNetworks.Terminality","page":"Traits","title":"DecisionNetworks.Terminality","text":"Terminality <: DecisionsTrait\nTerminality(::RVGroup)\n\nAbstract trait on a group of random variables indicating whether the corresponding distribution is expected to be able to produce Terminal() when sampled.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.Terminable","page":"Traits","title":"DecisionNetworks.Terminable","text":"Terminable <: Terminality\n\nTrait indicating a group of random variables might produce Terminal() under certain values of its conditioning variables.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.NotTerminable","page":"Traits","title":"DecisionNetworks.NotTerminable","text":"NotTerminable <: Terminality\n\nTrait indicating a group of random variables never produces Terminal() under any circumstances,.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#DecisionNetworks.MaybeTerminable","page":"Traits","title":"DecisionNetworks.MaybeTerminable","text":"MaybeTerminal <: Terminality\n\nTrait indicating a group of random variables may be able to produce Terminal() under some values of its conditioning variables, or for none of them.\n\n\n\n\n\n","category":"type"},{"location":"networks/traits.html#Traits-on-conditional-distributions","page":"Traits","title":"Traits on conditional distributions","text":"","category":"section"},{"location":"networks/traits.html","page":"Traits","title":"Traits","text":"todo: Todo\nNone exist yet. Determinism is the most relevant left to be implemented.","category":"page"},{"location":"networks/traits.html#Traits-on-spaces","page":"Traits","title":"Traits on spaces","text":"","category":"section"},{"location":"networks/traits.html","page":"Traits","title":"Traits","text":"todo: Todo\nNone exist yet. I think things like Finitude and Countability are reasonable,  but they're a low priority.","category":"page"},{"location":"index.html#Decisions.jl","page":"Decisions.jl","title":"Decisions.jl","text":"","category":"section"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"warning: Warning\nDecisions.jl is currently under active development in silent beta: it is publically accessible but not promoted or registered. Expect bugs and breaking changes. ","category":"page"},{"location":"index.html#What-is-Decisions.jl?","page":"Decisions.jl","title":"What is Decisions.jl?","text":"","category":"section"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"Decisions.jl is an ecosystem for canonical representations of decision problems. Using decision networks as the fundamental underlying structure, Decisions.jl provides an explicit interface for a rich set of decision problems: from the most basic Markov decision processes, to rich and expressive multi-agent, semi-Markov, multi-objective extensions, to complex problems unifying decision-, control-, and game-theoretic models.","category":"page"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"Decisions.jl is factored into three framework packages:","category":"page"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"DecisionNetworks.jl (beta) provides fundamental tools for the ecosystem: representations for decision networks, conditional distributions, support spaces, and visualizations.\nDecisionProblems.jl (beta) introduces objectives over decision networks and formal definitions of decision problems.\nDecisionSettings.jl (alpha) introduces real-world decision making scenarios, surgically defining concepts of agents, training loops, and environment interactions to permit truly exact comparisons between algorithms.","category":"page"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"... and two implementation packages:","category":"page"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"DecisionDomains.jl provides implementations of common baseline decision making domains for benchmarking.\nDecisionAlgorithms.jl provides off-the-shelf implementations of classic decision-making algorithm.","category":"page"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"If you're contributing to Decisions.jl, or you don't mind some unnecessary dependencies, the package Decisions itself reexports all names from the packages listed above, so you can just write using Decisions.","category":"page"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"Finally, Decisions.jl is a work in progress. Please report issues and feature requests on Github.","category":"page"},{"location":"index.html#Objectives","page":"Decisions.jl","title":"Objectives","text":"","category":"section"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"Decisions.jl is designed to be, in this order:","category":"page"},{"location":"index.html","page":"Decisions.jl","title":"Decisions.jl","text":"Definitive. Decision problems have precise mathematical definitions which are respected by Decisions.jl. It's easy to understand the exact specification of a given problem and compare algorithms on even footing.\nModular. Decision networks can be transformed, composed, stacked, and modified to create rich, expressive models. Algorithms designed for specific decision problems can be easily applied to extensions or simplifications of those problems. \nFast. Almost all of the overhead computation Decisions.jl uses to handle general decision networks is compile-time. Once compiled, all decision problems are first class, as efficiently used and sampled as any other.","category":"page"}]
}
